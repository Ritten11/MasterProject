{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def to_anomaly(data, rolling = 11):\n",
    "    \"\"\"\n",
    "    If no previously trained model is available, or if the available save file is corrupted, a new model needs to be\n",
    "    trained.\n",
    "    :param train_dat: Data needed for training the model\n",
    "    :return: A trained model\n",
    "    \"\"\"\n",
    "\n",
    "    grouped_data = data.groupby('time.month')\n",
    "\n",
    "    anomaly_per_month = {}\n",
    "    monthly_mean_dict = {}\n",
    "    for month, data in grouped_data:\n",
    "        df = data.to_dataframe()\n",
    "        monthly_rolling_mean = {}\n",
    "        for region, eco_dat in df.groupby('eco_regions'):\n",
    "            eco_dat = eco_dat.reset_index(level='eco_regions').drop(['eco_regions'], axis=1)\n",
    "            monthly_rolling_mean[region] = eco_dat.rolling(str(rolling*365.25)+'D', min_periods=1).mean()\n",
    "\n",
    "\n",
    "        monthly_mean_ds = xr.concat([df.to_xarray() for df in monthly_rolling_mean.values()], dim=pd.Index(data=monthly_rolling_mean.keys(), name=\"eco_regions\"))\n",
    "        monthly_mean_dict[month] = monthly_mean_ds\n",
    "        anomaly_per_month[month]=data-monthly_mean_ds\n",
    "    monthly_anomaly = xr.concat(anomaly_per_month.values(), dim='time').sortby('time')\n",
    "    return monthly_anomaly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    g10m_MAX   (eco_regions, time) float64 ...\n",
      "    swvl1_MIN  (eco_regions, time) float64 ...\n",
      "    swvl1_MAX  (eco_regions, time) float64 ...\n",
      "    slhf_MIN   (eco_regions, time) float64 ...\n",
      "    slhf_MAX   (eco_regions, time) float64 ...\n",
      "    slhf_AVG   (eco_regions, time) float64 ...\n",
      "    sshf_MIN   (eco_regions, time) float64 ...\n",
      "    sshf_MAX   (eco_regions, time) float64 ...\n",
      "    sshf_AVG   (eco_regions, time) float64 ...\n",
      "    ssrd_MIN   (eco_regions, time) float64 ...\n",
      "    ssrd_MAX   (eco_regions, time) float64 ...\n",
      "    ssrd_AVG   (eco_regions, time) float64 ...\n",
      "    u10m_AVG   (eco_regions, time) float64 ...\n",
      "    v10m_AVG   (eco_regions, time) float64 ...\n",
      "    blh_MAX    (eco_regions, time) float64 ...\n",
      "    d2m_MIN    (eco_regions, time) float64 ...\n",
      "    d2m_MAX    (eco_regions, time) float64 ...\n",
      "    d2m_AVG    (eco_regions, time) float64 ...\n",
      "    lsp_SUM    (eco_regions, time) float64 ...\n",
      "    skt_MIN    (eco_regions, time) float64 ...\n",
      "    skt_MAX    (eco_regions, time) float64 ...\n",
      "    skt_AVG    (eco_regions, time) float64 ...\n",
      "    src_MIN    (eco_regions, time) float64 ...\n",
      "    src_AVG    (eco_regions, time) float64 ...\n",
      "    ssr_MAX    (eco_regions, time) float64 ...\n",
      "    ssr_AVG    (eco_regions, time) float64 ...\n",
      "    t2m_MIN    (eco_regions, time) float64 ...\n",
      "    t2m_MAX    (eco_regions, time) float64 ...\n",
      "    t2m_AVG    (eco_regions, time) float64 ...\n",
      "    ci_AVG     (eco_regions, time) float64 ...\n",
      "    cp_MAX     (eco_regions, time) float64 ...\n",
      "    cp_SUM     (eco_regions, time) float64 ...\n",
      "    sd_MIN     (eco_regions, time) float64 ...\n",
      "    sd_MAX     (eco_regions, time) float64 ...\n",
      "    sf_AVG     (eco_regions, time) float64 ...\n",
      "    sf_MAX     (eco_regions, time) float64 ...\n",
      "    s10m_AVG   (eco_regions, time) float64 ...\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 1096, eco_regions: 68)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2000-01-01 2000-01-08 ... 2020-12-26\n",
      "  * eco_regions  (eco_regions) float64 1.0 3.0 4.0 7.0 ... 204.0 206.0 209.0\n",
      "Data variables: (12/37)\n",
      "    g10m_MAX     (eco_regions, time) float64 0.0 0.3509 -0.7395 ... -3.116 2.939\n",
      "    swvl1_MIN    (eco_regions, time) float64 0.0 -0.0001536 ... 0.00195\n",
      "    swvl1_MAX    (eco_regions, time) float64 0.0 -0.002324 ... 0.002162\n",
      "    slhf_MIN     (eco_regions, time) float64 0.0 -4.385 6.693 ... 47.35 -25.49\n",
      "    slhf_MAX     (eco_regions, time) float64 0.0 -2.097 -1.597 ... 10.18 -18.84\n",
      "    slhf_AVG     (eco_regions, time) float64 0.0 -0.2528 0.9785 ... 36.12 -28.07\n",
      "    ...           ...\n",
      "    cp_SUM       (eco_regions, time) float64 0.0 -5.374e-08 ... 2.69e-06\n",
      "    sd_MIN       (eco_regions, time) float64 0.0 0.006344 ... -0.0001915\n",
      "    sd_MAX       (eco_regions, time) float64 0.0 0.004085 ... -0.0002262\n",
      "    sf_AVG       (eco_regions, time) float64 0.0 -2.653e-09 ... 2.844e-11\n",
      "    sf_MAX       (eco_regions, time) float64 0.0 -1.481e-08 ... 2.051e-10\n",
      "    s10m_AVG     (eco_regions, time) float64 0.0 -0.1117 0.02411 ... -1.74 1.558\n"
     ]
    }
   ],
   "source": [
    "with xr.open_dataset('../data_files/vars_per_eco_update.nc') as ds:\n",
    "    pred_dat = ds.drop_vars(['regions', 'grid_cell_weight', 'grid_cell_area', 'TER', 'monthly_flux', 'smoothed_flux', 'opt_flux',\n",
    "                    'prior_flux_per_s', 'scaling_factor', 'sf_per_eco', 'monthly_sf', 'smoothed_sf', 'eco_area'])\n",
    "    remaining_vars = ds[['regions', 'grid_cell_weight', 'grid_cell_area', 'TER', 'monthly_flux', 'smoothed_flux', 'opt_flux',\n",
    "                    'prior_flux_per_s', 'scaling_factor', 'sf_per_eco', 'monthly_sf', 'smoothed_sf', 'eco_area']]\n",
    "print(pred_dat.data_vars)\n",
    "anomaly_data = to_anomaly(pred_dat[list(pred_dat.data_vars)[:37]]) # , mean_data\n",
    "\n",
    "print(anomaly_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_var_ds = xr.merge([remaining_vars, anomaly_data])\n",
    "\n",
    "file_name= '../data_files/vars_per_eco_monthly_anomaly.nc'\n",
    "with open(file_name, 'wb') as out:\n",
    "    new_var_ds.to_netcdf(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
