{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import xarray as xr # needed for reading data\n",
    "import pandas as pd # Used for stroing data\n",
    "import numpy as np\n",
    "import pickle as pkl  # Needed for saving model objects\n",
    "import os\n",
    "from itertools import repeat # Needed for repeating a variable multiple times\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm    # Used for bot he SARIMA and SARIMAX models\n",
    "from sklearn import metrics     # Used for importing various performance measures\n",
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Depending on the machine on which the code is run, data might be stored in different directories.\n",
    "# Indicate which machine is used to make sure the path to the data can be found.\n",
    "# Can either be \"local\" or \"Snellius\"\n",
    "\n",
    "MACHINE = 'Snellius'\n",
    "\n",
    "if MACHINE == 'Snellius':\n",
    "    pred_var_path = '/gpfs/work1/0/ctdas/awoude/Ritten/predictor_vars/' # For retrieving the set of aggregated scaling vectors\n",
    "\n",
    "    save_dir = pers_file_dir = '/gpfs/work1/0/ctdas/awoude/Ritten/trained_models/' # used for storing the trained model\n",
    "\n",
    "    results_dir = '/gpfs/work1/0/ctdas/awoude/Ritten/results/' # used for storing the trained model\n",
    "\n",
    "elif MACHINE == 'local':\n",
    "    pred_var_path = './' # For retrieving the set of aggregated scaling vectors\n",
    "\n",
    "    save_dir = pers_file_dir = './models/' # used for storing the trained model\n",
    "\n",
    "    results_dir = './results/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(model, dat, model_name, test_or_train, show_fit=False):\n",
    "    '''\n",
    "    Evaluate the model using the provided testing data\n",
    "    :param model: The model which is to be tested\n",
    "    :param dat: The data that is to be used for testing the model. Also includes any predictor variables.\n",
    "                Can both be used for testing the fit on both trianing data and testing data\n",
    "    :param model_name: The used ML-algorithm\n",
    "    :param test_or_train: Flag to indicate whether the passed data is training data ot testing data\n",
    "    :param show_fit: Flag to indicate whether a plot of the fit should be provided\n",
    "    :return:\n",
    "    '''\n",
    "    flux_dat = dat.prior_flux_per_s.values\n",
    "    if model_name == \"SARIMA\":\n",
    "        true_dat = dat.sf_per_eco.values\n",
    "        if test_or_train == 'test':\n",
    "            start_index = len(model.fittedvalues)\n",
    "            final_model = model.append(true_dat)\n",
    "        elif test_or_train == 'train':\n",
    "            start_index = 0\n",
    "            final_model = model\n",
    "        else:\n",
    "            raise Exception(f'test_or_train not specified:{test_or_train}')\n",
    "        prediction = final_model.get_prediction(start=start_index)\n",
    "        predict_ci = prediction.conf_int()\n",
    "        pred_dat = prediction.predicted_mean\n",
    "        if show_fit:\n",
    "\n",
    "            # Graph\n",
    "            fig, ax = plt.subplots(figsize=(9,4))\n",
    "            title = test_or_train + ' data: predicted sf of ecoregion ' + str(dat.eco_regions.values)\n",
    "            ax.set(title=title, xlabel='Date', ylabel='Scaling factor')\n",
    "\n",
    "            # Plot data points\n",
    "            dat.plot.scatter(x='time',y='sf_per_eco', ax=ax, label='Observed', c='C00')\n",
    "            # Plot predictions\n",
    "            plt.plot(dat.time.values, pred_dat, label='One-step-ahead forecast', c='C01')\n",
    "            ci = predict_ci\n",
    "            ax.fill_between(dat.time.values, ci[:,0], ci[:,1], color='C01', alpha=0.1)\n",
    "\n",
    "            legend = ax.legend(loc='lower right')\n",
    "\n",
    "            plt.show()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Model evaluation of {model_name} not implemented')\n",
    "\n",
    "    # Make sure all provided datasets heve the same length\n",
    "    assert (len(true_dat)==len(pred_dat)) and (len(true_dat)==len(flux_dat)), 'Passed datasets are do not have the same length'\n",
    "\n",
    "    # Determine the performance in scaling factor space\n",
    "    sf_ME = (np.sum(true_dat)-np.sum(pred_dat))/len(true_dat)\n",
    "    sf_MAE = metrics.mean_absolute_error(true_dat, pred_dat)\n",
    "    sf_MAPE = metrics.mean_absolute_percentage_error(true_dat, pred_dat)\n",
    "    sf_RMSE = np.sqrt(metrics.mean_squared_error(true_dat, pred_dat))\n",
    "    sf_r2 = metrics.r2_score(true_dat, pred_dat)\n",
    "\n",
    "    # Move evaluation to flux space\n",
    "    true_flux = true_dat * flux_dat\n",
    "    pred_flux = pred_dat * flux_dat\n",
    "\n",
    "    # Determine the performance in flux space\n",
    "    flux_ME = (np.sum(true_dat)-np.sum(pred_flux))/len(true_dat)\n",
    "    flux_MAE = metrics.mean_absolute_error(true_flux, pred_flux)\n",
    "    flux_MAPE = metrics.mean_absolute_percentage_error(true_flux, pred_flux)\n",
    "    flux_RMSE = np.sqrt(metrics.mean_squared_error(true_flux, pred_flux))\n",
    "    flux_r2 = metrics.r2_score(true_flux, pred_flux)\n",
    "    return {'sf_ME_'+test_or_train:sf_ME,\n",
    "           'sf_MAE_'+test_or_train:sf_MAE,\n",
    "           'sf_MAPE_'+test_or_train:sf_MAPE,\n",
    "           'sf_RMSE_'+test_or_train:sf_RMSE,\n",
    "           'sf_r2_'+test_or_train:sf_r2,\n",
    "           'flux_ME_'+test_or_train:flux_ME,\n",
    "           'flux_MAE_'+test_or_train:flux_MAE,\n",
    "           'flux_MAPE_'+test_or_train:flux_MAPE,\n",
    "           'flux_RMSE_'+test_or_train:flux_RMSE,\n",
    "           'flux_r2_'+test_or_train:flux_r2}\n",
    "\n",
    "\n",
    "def write_model(model, model_name, start_year, eco_region):\n",
    "    '''\n",
    "    Function used to save a model in the correct directory with an identifiable name. Uses Pickle for saving the model object\n",
    "    :param model: The model which is to be saved\n",
    "    :param model_name: The used ML-algorithm\n",
    "    :param start_year: The date at which the training data starts\n",
    "    :param eco_region: The name of the ecoregion to which the model applies\n",
    "    :return: None\n",
    "    '''\n",
    "    file_name = model_name+'_'+str(eco_region)+'.pkl'\n",
    "    file_dir = save_dir+model_name+'/'+start_year+'/'\n",
    "    if not os.path.isdir(file_dir):\n",
    "        os.makedirs(file_dir)\n",
    "    file = file_dir + file_name\n",
    "    pkl.dump(model, open(file, \"wb\"))\n",
    "\n",
    "def train_model(train_dat, model_name, eco_region):\n",
    "    '''\n",
    "    Function for training a model on the provided training data\n",
    "    :param train_dat: The data used for training. Includes both target data and predictor data\n",
    "    :param model_name: Name of the ML-algorithm to be used for training\n",
    "    :return: A trianed model\n",
    "    '''\n",
    "    if model_name == 'SARIMA':\n",
    "        target_data = train_dat.sf_per_eco\n",
    "        model = sm.tsa.statespace.SARIMAX(target_data.values,\n",
    "                                         order=(2,0,2),             # Defining the regular AR, I and MA dependencies\n",
    "                                         seasonal_order=(1,0,1,52),     # Defining the seasonal dependencies\n",
    "                                         trend = 'c'                # Adding an intercept term)\n",
    "                                          )\n",
    "        fitted_model=model.fit(maxiter=100) # method='cg'\n",
    "    else:\n",
    "        raise NotImplementedError(f'Training of model {model_name} has not been implemented')\n",
    "#     eco_region = str(train_dat.eco_regions.values)\n",
    "    start_year = str(train_dat.time.dt.year.min().values)\n",
    "\n",
    "    # Save model for future usage\n",
    "    write_model(fitted_model, model_name, start_year, eco_region)\n",
    "    return fitted_model\n",
    "\n",
    "def test_eco_region(eco_dat, model_name):\n",
    "    region, data = eco_dat\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    #Set aside the testing data. Using the classical 80%-20% split\n",
    "    test_ds = data.loc[dict(time=slice(\"2017\", \"2020\"))]\n",
    "    region_dat = data.loc[dict(time=slice(\"2000\", \"2016\"))]\n",
    "    for year in range(2000, 2017):\n",
    "\n",
    "        # Determine training data and train model\n",
    "        train_ds = region_dat.loc[dict(time=slice(str(year), \"2016\"))]\n",
    "        trained_model = train_model(train_ds, model_name, region)\n",
    "\n",
    "        # Evaluate the model, both on training and testing data\n",
    "        train_results = eval_model(trained_model, train_ds, model_name, 'train', show_fit=False)\n",
    "        test_results = eval_model(trained_model, test_ds, model_name, 'test', show_fit=False)\n",
    "        model_params = {\n",
    "                'eco_region':region,\n",
    "                'start_year':year,\n",
    "                'N_train_years':(2017-year),\n",
    "                'N_train_obs':len(train_ds.time),\n",
    "                'N_test_years':4,\n",
    "                'N_test_obs':len(test_ds.time)\n",
    "        }\n",
    "\n",
    "        # unpack all dicts to form single results dict\n",
    "        model_results = {**model_params, **train_results, **test_results}\n",
    "        if len(results_df) == 0:\n",
    "            results_df = pd.DataFrame(model_results, index=[0])\n",
    "        else:\n",
    "            results_df = results_df.append(model_results, ignore_index=True)\n",
    "    return results_df\n",
    "\n",
    "def run_model(model_name, complete_ds):\n",
    "    eco_region_dat = list(complete_ds.groupby(\"eco_regions\"))\n",
    "    eco_region_dat = [(region, data.load(scheduler='sync')) for region, data in eco_region_dat]\n",
    "    with Pool(32) as pool:\n",
    "        list_of_results = pool.starmap(test_eco_region, zip(eco_region_dat, repeat(model_name)))\n",
    "    results = pd.concat(list_of_results)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.pyenv/versions/MasterProject-3.9.2/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:997: UserWarning: Non-stationary starting seasonal autoregressive Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting seasonal autoregressive'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            8     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.14392D+00    |proj g|=  4.53536D-02\n",
      "\n",
      "At iterate    5    f=  2.13984D+00    |proj g|=  3.60068D-03\n",
      "\n",
      "At iterate   10    f=  2.13982D+00    |proj g|=  3.08541D-04\n",
      "\n",
      "At iterate   15    f=  2.13981D+00    |proj g|=  1.05633D-03\n",
      "\n",
      "At iterate   20    f=  2.13981D+00    |proj g|=  2.85639D-05\n",
      "\n",
      "At iterate   25    f=  2.13981D+00    |proj g|=  5.42024D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    8     29     32      1     0     0   9.612D-06   2.140D+00\n",
      "  F =   2.1398112047890794     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "./models/SARIMA/2013/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.pyenv/versions/MasterProject-3.9.2/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:997: UserWarning: Non-stationary starting seasonal autoregressive Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting seasonal autoregressive'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            8     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.96553D+00    |proj g|=  8.50912D-02\n",
      "\n",
      "At iterate    5    f=  1.95364D+00    |proj g|=  2.01117D-03\n",
      "\n",
      "At iterate   10    f=  1.95338D+00    |proj g|=  5.47923D-03\n",
      "\n",
      "At iterate   15    f=  1.95333D+00    |proj g|=  4.15037D-04\n",
      "\n",
      "At iterate   20    f=  1.95331D+00    |proj g|=  3.48639D-03\n",
      "\n",
      "At iterate   25    f=  1.95329D+00    |proj g|=  1.27797D-04\n",
      "\n",
      "At iterate   30    f=  1.95329D+00    |proj g|=  4.25403D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    8     31     52      1     0     0   4.254D-05   1.953D+00\n",
      "  F =   1.9532915421877590     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/SARIMA/2014/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43658/3781297434.py:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(model_results, ignore_index=True)\n",
      "/home/user/.pyenv/versions/MasterProject-3.9.2/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/home/user/.pyenv/versions/MasterProject-3.9.2/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/home/user/.pyenv/versions/MasterProject-3.9.2/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            8     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.13343D+00    |proj g|=  7.24490D-02\n",
      "\n",
      "At iterate    5    f=  2.12559D+00    |proj g|=  1.13357D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    8      9     11      1     0     0   4.748D-05   2.126D+00\n",
      "  F =   2.1255879829581139     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "./models/SARIMA/2015/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43658/3781297434.py:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(model_results, ignore_index=True)\n",
      "/home/user/.pyenv/versions/MasterProject-3.9.2/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/home/user/.pyenv/versions/MasterProject-3.9.2/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/home/user/.pyenv/versions/MasterProject-3.9.2/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            8     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.45712D+00    |proj g|=  4.71729D-02\n",
      "\n",
      "At iterate    5    f=  2.45079D+00    |proj g|=  1.69062D-03\n",
      "\n",
      "At iterate   10    f=  2.45051D+00    |proj g|=  9.41503D-03\n",
      "\n",
      "At iterate   15    f=  2.43861D+00    |proj g|=  3.05342D-02\n",
      "\n",
      "At iterate   20    f=  2.43403D+00    |proj g|=  2.20849D-02\n",
      "\n",
      "At iterate   25    f=  2.42899D+00    |proj g|=  8.03576D-03\n",
      "\n",
      "At iterate   30    f=  2.42353D+00    |proj g|=  4.90617D-02\n",
      "\n",
      "At iterate   35    f=  2.41851D+00    |proj g|=  7.62160D-02\n",
      "\n",
      "At iterate   40    f=  2.41269D+00    |proj g|=  9.91614D-02\n",
      "\n",
      "At iterate   45    f=  2.40803D+00    |proj g|=  1.69257D-01\n",
      "\n",
      "At iterate   50    f=  2.40220D+00    |proj g|=  1.21649D-01\n",
      "\n",
      "At iterate   55    f=  2.39590D+00    |proj g|=  2.47784D-01\n",
      "\n",
      "At iterate   60    f=  2.38767D+00    |proj g|=  1.01321D+00\n",
      "\n",
      "At iterate   65    f=  2.37919D+00    |proj g|=  9.00362D-01\n",
      "\n",
      "At iterate   70    f=  2.37339D+00    |proj g|=  8.75867D+00\n",
      "\n",
      "At iterate   75    f=  2.37093D+00    |proj g|=  8.99590D+00\n",
      "\n",
      "At iterate   80    f=  2.36704D+00    |proj g|=  4.54088D+00\n",
      "\n",
      "At iterate   85    f=  2.36659D+00    |proj g|=  4.55601D-01\n",
      "\n",
      "At iterate   90    f=  2.36453D+00    |proj g|=  1.54084D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    8     91    169      1     0     0   1.541D+00   2.365D+00\n",
      "  F =   2.3645303366372765     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "./models/SARIMA/2016/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      "/tmp/ipykernel_43658/3781297434.py:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(model_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading all necessary data\n",
    "with xr.open_dataset(pred_var_path + 'vars_per_eco_update.nc') as ds:\n",
    "    complete_ds = ds\n",
    "\n",
    "results = run_model('SARIMA', complete_ds)\n",
    "\n",
    "results_file = results_dir + 'SARIMA_results.pkl'\n",
    "print(results)\n",
    "\n",
    "results.to_pickle(results_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eco_region</th>\n",
       "      <th>start_year</th>\n",
       "      <th>N_train_years</th>\n",
       "      <th>N_train_obs</th>\n",
       "      <th>N_test_years</th>\n",
       "      <th>N_test_obs</th>\n",
       "      <th>sf_ME_train</th>\n",
       "      <th>sf_MAE_train</th>\n",
       "      <th>sf_MAPE_train</th>\n",
       "      <th>sf_RMSE_train</th>\n",
       "      <th>...</th>\n",
       "      <th>sf_ME_test</th>\n",
       "      <th>sf_MAE_test</th>\n",
       "      <th>sf_MAPE_test</th>\n",
       "      <th>sf_RMSE_test</th>\n",
       "      <th>sf_r2_test</th>\n",
       "      <th>flux_ME_test</th>\n",
       "      <th>flux_MAE_test</th>\n",
       "      <th>flux_MAPE_test</th>\n",
       "      <th>flux_RMSE_test</th>\n",
       "      <th>flux_r2_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.644575</td>\n",
       "      <td>1.295177</td>\n",
       "      <td>2.056528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346716</td>\n",
       "      <td>0.580514</td>\n",
       "      <td>2.953288</td>\n",
       "      <td>1.649151</td>\n",
       "      <td>-0.039344</td>\n",
       "      <td>11042.820172</td>\n",
       "      <td>7.781078e+05</td>\n",
       "      <td>2.953288</td>\n",
       "      <td>1.123800e+06</td>\n",
       "      <td>0.735286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>-0.017847</td>\n",
       "      <td>0.550743</td>\n",
       "      <td>1.486765</td>\n",
       "      <td>1.692845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279184</td>\n",
       "      <td>0.588122</td>\n",
       "      <td>3.270719</td>\n",
       "      <td>1.674181</td>\n",
       "      <td>-0.071133</td>\n",
       "      <td>79923.982846</td>\n",
       "      <td>7.332844e+05</td>\n",
       "      <td>3.270719</td>\n",
       "      <td>1.060300e+06</td>\n",
       "      <td>0.764356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>-0.015599</td>\n",
       "      <td>0.598733</td>\n",
       "      <td>1.290804</td>\n",
       "      <td>2.015637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400903</td>\n",
       "      <td>0.613941</td>\n",
       "      <td>2.910919</td>\n",
       "      <td>1.679332</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>47813.462841</td>\n",
       "      <td>8.190713e+05</td>\n",
       "      <td>2.910919</td>\n",
       "      <td>1.190525e+06</td>\n",
       "      <td>0.702919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>-0.192008</td>\n",
       "      <td>0.760977</td>\n",
       "      <td>0.771617</td>\n",
       "      <td>2.813117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.153573</td>\n",
       "      <td>1.808462</td>\n",
       "      <td>5.319124</td>\n",
       "      <td>3.352715</td>\n",
       "      <td>-3.295678</td>\n",
       "      <td>-664725.411662</td>\n",
       "      <td>2.688521e+06</td>\n",
       "      <td>5.319124</td>\n",
       "      <td>4.172654e+06</td>\n",
       "      <td>-2.649416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   eco_region  start_year  N_train_years  N_train_obs  N_test_years  \\\n",
       "0         1.0      2013.0            4.0        209.0           4.0   \n",
       "1         1.0      2014.0            3.0        157.0           4.0   \n",
       "2         1.0      2015.0            2.0        105.0           4.0   \n",
       "3         1.0      2016.0            1.0         53.0           4.0   \n",
       "\n",
       "   N_test_obs  sf_ME_train  sf_MAE_train  sf_MAPE_train  sf_RMSE_train  ...  \\\n",
       "0       208.0     0.001326      0.644575       1.295177       2.056528  ...   \n",
       "1       208.0    -0.017847      0.550743       1.486765       1.692845  ...   \n",
       "2       208.0    -0.015599      0.598733       1.290804       2.015637  ...   \n",
       "3       208.0    -0.192008      0.760977       0.771617       2.813117  ...   \n",
       "\n",
       "   sf_ME_test  sf_MAE_test  sf_MAPE_test  sf_RMSE_test  sf_r2_test  \\\n",
       "0    0.346716     0.580514      2.953288      1.649151   -0.039344   \n",
       "1    0.279184     0.588122      3.270719      1.674181   -0.071133   \n",
       "2    0.400903     0.613941      2.910919      1.679332   -0.077734   \n",
       "3    1.153573     1.808462      5.319124      3.352715   -3.295678   \n",
       "\n",
       "    flux_ME_test  flux_MAE_test  flux_MAPE_test  flux_RMSE_test  flux_r2_test  \n",
       "0   11042.820172   7.781078e+05        2.953288    1.123800e+06      0.735286  \n",
       "1   79923.982846   7.332844e+05        3.270719    1.060300e+06      0.764356  \n",
       "2   47813.462841   8.190713e+05        2.910919    1.190525e+06      0.702919  \n",
       "3 -664725.411662   2.688521e+06        5.319124    4.172654e+06     -2.649416  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(results_dir+file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}